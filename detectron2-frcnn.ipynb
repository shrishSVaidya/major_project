{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8576611,"sourceType":"datasetVersion","datasetId":5051258}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-01T09:05:46.488195Z","iopub.execute_input":"2024-06-01T09:05:46.489101Z","iopub.status.idle":"2024-06-01T09:05:47.362992Z","shell.execute_reply.started":"2024-06-01T09:05:46.489060Z","shell.execute_reply":"2024-06-01T09:05:47.361946Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install pyyaml==5.1\n\nimport torch\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n# Install detectron2 that matches the above pytorch version\n# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/TORCH_VERSION/index.html\n# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime\n     ","metadata":{"execution":{"iopub.status.busy":"2024-06-01T09:05:47.365044Z","iopub.execute_input":"2024-06-01T09:05:47.365492Z","iopub.status.idle":"2024-06-01T09:07:58.518354Z","shell.execute_reply.started":"2024-06-01T09:05:47.365463Z","shell.execute_reply":"2024-06-01T09:07:58.517135Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pyyaml==5.1\n  Downloading PyYAML-5.1.tar.gz (274 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[34 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-w7yhbf5e/pyyaml_bb1b2769b2774b0993647dd2e9b405a7/setup.py\", line 291, in <module>\n  \u001b[31m   \u001b[0m     setup(\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n  \u001b[31m   \u001b[0m     return run_commands(dist)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n  \u001b[31m   \u001b[0m     dist.run_commands()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n  \u001b[31m   \u001b[0m     self.run_command(cmd)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 963, in run_command\n  \u001b[31m   \u001b[0m     super().run_command(command)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n  \u001b[31m   \u001b[0m     cmd_obj.run()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 321, in run\n  \u001b[31m   \u001b[0m     self.find_sources()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 329, in find_sources\n  \u001b[31m   \u001b[0m     mm.run()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 551, in run\n  \u001b[31m   \u001b[0m     self.add_defaults()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 589, in add_defaults\n  \u001b[31m   \u001b[0m     sdist.add_defaults(self)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/sdist.py\", line 112, in add_defaults\n  \u001b[31m   \u001b[0m     super().add_defaults()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/sdist.py\", line 251, in add_defaults\n  \u001b[31m   \u001b[0m     self._add_defaults_ext()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/sdist.py\", line 336, in _add_defaults_ext\n  \u001b[31m   \u001b[0m     self.filelist.extend(build_ext.get_source_files())\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-w7yhbf5e/pyyaml_bb1b2769b2774b0993647dd2e9b405a7/setup.py\", line 199, in get_source_files\n  \u001b[31m   \u001b[0m     self.cython_sources(ext.sources, ext)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 107, in __getattr__\n  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n  \u001b[31m   \u001b[0m AttributeError: cython_sources\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25htorch:  2.1 ; cuda:  2.1.2\nCollecting git+https://github.com/facebookresearch/detectron2.git\n  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-_p_3qml1\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-_p_3qml1\n  Resolved https://github.com/facebookresearch/detectron2.git to commit 0df2d73d0013db7de629602c23cc120219b4f2b8\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (9.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (3.7.5)\nCollecting pycocotools>=2.0.2 (from detectron2==0.6)\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.4.0)\nCollecting yacs>=0.1.8 (from detectron2==0.6)\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (0.9.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.2.1)\nRequirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (4.66.1)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.15.1)\nCollecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\nCollecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting hydra-core>=1.1 (from detectron2==0.6)\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nCollecting black (from detectron2==0.6)\n  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\nCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (8.1.7)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (1.0.0)\nCollecting packaging (from detectron2==0.6)\n  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\nCollecting pathspec>=0.9.0 (from black->detectron2==0.6)\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (4.2.0)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (2.0.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (4.9.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.5.2)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.31.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.0.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\nDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n  Building wheel for detectron2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=1261472 sha256=96bc30c0e6bf987c09801f91c8602aa810eec8e27056e73e4c42f700f770096d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-rd6kz134/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=d5a9f3c1fc77d863aaa23112598d6bcb86e6698e9e9d563e1855ce4776cc6fa4\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=df6a1037155654c7c9fa04316f15b72180ade884823105fdfdc86e2fe518990c\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built detectron2 fvcore antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, packaging, omegaconf, iopath, hydra-core, black, pycocotools, fvcore, detectron2\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.0 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 black-24.4.2 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 omegaconf-2.3.0 packaging-24.0 pathspec-0.12.1 portalocker-2.8.2 pycocotools-2.0.7 yacs-0.1.8\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install pylabel","metadata":{"execution":{"iopub.status.busy":"2024-06-01T09:07:58.519892Z","iopub.execute_input":"2024-06-01T09:07:58.520566Z","iopub.status.idle":"2024-06-01T09:07:58.525277Z","shell.execute_reply.started":"2024-06-01T09:07:58.520537Z","shell.execute_reply":"2024-06-01T09:07:58.524373Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# from pylabel import importer\n# import os, zipfile\n\n# path_to_annotations = '/kaggle/input/fish-market-dataset/Fish_dataset/Dataset/labels/test'\n\n# #Identify the path to get from the annotations to the images \n# path_to_images = '/kaggle/input/fish-market-dataset/Fish_dataset/Dataset/images/test'\n\n# classes = [\n# 'Rui',\n# 'Bhakur,Bhakua,catla',\n# 'Mrigal,Mirika',\n# 'Ilish',\n# 'Chitol',\n# 'Borali',\n# 'Sippi,Pengha/pengba',\n# 'korang',\n# 'Kangon,Tunti,Vacha,basa',\n# 'Kundali(assam),Chitol(bangladesh),Foli(WB)',\n# 'khas',\n# 'Bou mach',\n# 'Chuno',\n# 'kaliara,kalisasu,mali,mahlee',\n# 'Telapia',\n# 'Boaal',\n# 'Nur Pur',\n# 'Puiya',\n# 'Sapla pata',\n# 'Shutki',\n# 'Telia(Odia),ghol',\n# 'Borguni',\n# 'pabda,godalae(kanada),khababia(khasi)',\n# 'Pakal Mach',\n# 'Shol mach',\n# 'Karati, Chapila, Karoti, Khoira',\n# 'rup chada',\n# 'Ari',\n# 'Gagol',\n# 'Gura tengra',\n# 'Litha',\n# 'Bangladeshi (Native)',\n# 'Kadali/kondali',\n# 'bacha',\n# 'bordaia',\n# 'koi',\n# 'bami',\n# 'Lomba chanda',\n# 'loitta',\n# 'tuna',\n# 'vetki',\n# 'batasi',\n# 'pangas',\n# 'hatir kaan',\n# 'aom machh',\n# 'pann mach',\n# 'sadha mach',\n# 'chan chanda',\n# 'sonali bata',\n# 'tapsi',\n# 'pomfret',\n# 'gagnga tope',\n# 'Tural turi/pankal(Bengali),pakal baim',\n# 'Kholihona',\n# 'Ptimutura',\n# 'keshi',\n# 'Silver carp',\n# 'Singi,Magur',\n# 'Neftani',\n# 'Keyakeatta',\n# 'Neria',\n# 'Nau matchee',\n# 'Lobura',\n# 'Phabounga',\n# 'Cheniputhi',\n# 'Hato/Hamto',\n# 'Bokar',\n# 'Kurhi/kuria',\n# 'Bhangone/bata mach',\n# 'Chapa Kori',\n# 'lambu/poa',\n# 'Tolar Aandi',\n# 'Guraicha/chingri',\n# 'Baila',\n# 'Sada Aatina',\n# 'kakia',\n# 'potka/Dichotomyctere nigroviridis(english)',\n# 'choukya',\n# 'khorul bata/parshe(bengali)',\n# 'nuna tangra',\n# 'kata mach',\n# 'kukkurish',\n# 'Salo Ichalo',\n# 'laupati',\n# 'selkona',\n# 'mouah/bariala',\n# 'Puti',\n# 'AArikana',\n# 'Balisonda lozola',\n# 'Moa',\n# 'Shillong(fish)',\n# 'Goti poa',\n# 'eel',\n# 'horse mackerel',\n# 'kingfish',\n# 'Sardine',\n# 'Trout'\n# ]\n\n# dataset = importer.ImportYoloV5(path=path_to_annotations, path_to_images=path_to_images, cat_names=classes, img_ext='jpg,jpeg,png', name='coco128')\n\n# print(dataset.df.head())\n\n# dataset.export.ExportToCoco(output_path='/kaggle/working/', cat_id_index=1)\n\n# # import cv2\n\n# # im = cv2.imread('E:\\\\major\\\\data\\\\Dataset\\\\images\\\\train\\\\15_107.jpg')\n# # print(im.shape[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T09:07:58.527666Z","iopub.execute_input":"2024-06-01T09:07:58.528044Z","iopub.status.idle":"2024-06-01T09:07:58.543096Z","shell.execute_reply.started":"2024-06-01T09:07:58.528009Z","shell.execute_reply":"2024-06-01T09:07:58.542357Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog","metadata":{"execution":{"iopub.status.busy":"2024-06-01T09:07:58.544169Z","iopub.execute_input":"2024-06-01T09:07:58.544617Z","iopub.status.idle":"2024-06-01T09:08:02.070415Z","shell.execute_reply.started":"2024-06-01T09:07:58.544593Z","shell.execute_reply":"2024-06-01T09:08:02.069490Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nfrom detectron2.data.datasets import register_coco_instances\nregister_coco_instances(\"my_dataset_train2\", {}, \"/kaggle/input/fish-market-dataset/train.json\", \"/kaggle/input/fish-market-dataset/Fish_dataset/Dataset/images/train\")\nregister_coco_instances(\"my_dataset_test2\", {}, \"/kaggle/input/fish-market-dataset/test.json\", \"/kaggle/input/fish-market-dataset/Fish_dataset/Dataset/images/test\")\nregister_coco_instances(\"my_dataset_val2\", {}, \"/kaggle/input/fish-market-dataset/val.json\", \"/kaggle/input/fish-market-dataset/Fish_dataset/Dataset/images/val\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T09:08:02.071884Z","iopub.execute_input":"2024-06-01T09:08:02.072407Z","iopub.status.idle":"2024-06-01T09:08:02.077405Z","shell.execute_reply.started":"2024-06-01T09:08:02.072372Z","shell.execute_reply":"2024-06-01T09:08:02.076364Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\"))\ncfg.DATASETS.TRAIN = (\"my_dataset_train2\",)\ncfg.DATASETS.TEST = (\"my_dataset_val2\",)\ncfg.TEST.EVAL_PERIOD = 100\ncfg.DATALOADER.NUM_WORKERS = 2\n\nTOTAL=4368\nEPOCHS=50\n\n\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 8\ncfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\ncfg.SOLVER.MAX_ITER = int((EPOCHS*TOTAL)/8)   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n\n# cfg.SOLVER.MAX_ITER = TOTAL * EPOCHS/8\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 97  # (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg)\ntrainer.resume_or_load(resume=True)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T09:08:02.079740Z","iopub.execute_input":"2024-06-01T09:08:02.080075Z","iopub.status.idle":"2024-06-01T09:12:57.648338Z","shell.execute_reply.started":"2024-06-01T09:08:02.080035Z","shell.execute_reply":"2024-06-01T09:12:57.646906Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[32m[06/01 09:08:03 d2.engine.defaults]: \u001b[0mModel:\nGeneralizedRCNN(\n  (backbone): ResNet(\n    (stem): BasicStem(\n      (conv1): Conv2d(\n        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n      )\n    )\n    (res2): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv1): Conv2d(\n          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n      )\n    )\n    (res3): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n        (conv1): Conv2d(\n          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n      )\n      (3): BottleneckBlock(\n        (conv1): Conv2d(\n          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n      )\n    )\n    (res4): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n        )\n        (conv1): Conv2d(\n          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n        )\n      )\n      (3): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n        )\n      )\n      (4): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n        )\n      )\n      (5): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n        )\n      )\n    )\n  )\n  (proposal_generator): RPN(\n    (rpn_head): StandardRPNHead(\n      (conv): Conv2d(\n        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n        (activation): ReLU()\n      )\n      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (anchor_generator): DefaultAnchorGenerator(\n      (cell_anchors): BufferList()\n    )\n  )\n  (roi_heads): Res5ROIHeads(\n    (pooler): ROIPooler(\n      (level_poolers): ModuleList(\n        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n      )\n    )\n    (res5): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n        )\n        (conv1): Conv2d(\n          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n        (conv2): Conv2d(\n          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n        )\n        (conv3): Conv2d(\n          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n        )\n      )\n    )\n    (box_predictor): FastRCNNOutputLayers(\n      (cls_score): Linear(in_features=2048, out_features=98, bias=True)\n      (bbox_pred): Linear(in_features=2048, out_features=388, bias=True)\n    )\n  )\n)\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/01 09:08:03 d2.data.datasets.coco]: \u001b[0m/kaggle/input/fish-market-dataset/train.json contains 14281 annotations, but only 14280 of them match to images in the file.\n\u001b[32m[06/01 09:08:03 d2.data.datasets.coco]: \u001b[0mLoaded 4363 images in COCO format from /kaggle/input/fish-market-dataset/train.json\n\u001b[32m[06/01 09:08:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4363 images left.\n\u001b[32m[06/01 09:08:03 d2.data.build]: \u001b[0mDistribution of instances among all 97 categories:\n\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n|      Rui      | 1188         | Bhakur,Bhak.. | 609          | Mrigal,Mirika | 90           |\n|     Ilish     | 454          |    Chitol     | 304          |    Borali     | 52           |\n| Sippi,Pengh.. | 30           |    korang     | 19           | Kangon,Tunt.. | 52           |\n| Kundali(ass.. | 44           |     khas      | 23           |   Bou mach    | 55           |\n|     Chuno     | 70           | kaliara,kal.. | 50           |    Telapia    | 470          |\n|     Boaal     | 106          |    Nur Pur    | 29           |     Puiya     | 49           |\n|  Sapla pata   | 65           |    Shutki     | 152          | Telia(Odia).. | 77           |\n|    Borguni    | 185          | pabda,godal.. | 706          |  Pakal Mach   | 150          |\n|   Shol mach   | 472          | Karati, Cha.. | 93           |   rup chada   | 231          |\n|      Ari      | 231          |     Gagol     | 9            |  Gura tengra  | 28           |\n|     Litha     | 51           | Bangladeshi.. | 52           | Kadali/kond.. | 74           |\n|     bacha     | 160          |    bordaia    | 22           |      koi      | 1051         |\n|     bami      | 38           | Lomba chanda  | 55           |    loitta     | 114          |\n|     tuna      | 74           |     vetki     | 73           |    batasi     | 84           |\n|    pangas     | 42           |  hatir kaan   | 211          |   aom machh   | 24           |\n|   pann mach   | 4            |  sadha mach   | 71           |  chan chanda  | 76           |\n|  sonali bata  | 210          |     tapsi     | 21           |    pomfret    | 236          |\n|  gagnga tope  | 20           | Tural turi/.. | 69           |   Kholihona   | 91           |\n|   Ptimutura   | 62           |     keshi     | 38           |  Silver carp  | 71           |\n|  Singi,Magur  | 283          |    Neftani    | 38           |  Keyakeatta   | 30           |\n|     Neria     | 127          |  Nau matchee  | 21           |    Lobura     | 25           |\n|   Phabounga   | 8            |  Cheniputhi   | 28           |  Hato/Hamto   | 25           |\n|     Bokar     | 71           |  Kurhi/kuria  | 40           | Bhangone/ba.. | 1514         |\n|  Chapa Kori   | 106          |   lambu/poa   | 98           |  Tolar Aandi  | 34           |\n| Guraicha/ch.. | 304          |     Baila     | 16           |  Sada Aatina  | 187          |\n|     kakia     | 73           | potka/Dicho.. | 62           |    choukya    | 59           |\n| khorul bata.. | 96           |  nuna tangra  | 38           |   kata mach   | 14           |\n|   kukkurish   | 11           |  Salo Ichalo  | 14           |    laupati    | 33           |\n|    selkona    | 24           | mouah/bariala | 8            |     Puti      | 62           |\n|   AArikana    | 21           | Balisonda l.. | 33           |      Moa      | 1130         |\n| Shillong(fi.. | 21           |   Goti poa    | 69           |      eel      | 87           |\n| horse macke.. | 88           |   kingfish    | 62           |    Sardine    | 59           |\n|     Trout     | 74           |               |              |               |              |\n|     total     | 14280        |               |              |               |              |\u001b[0m\n\u001b[32m[06/01 09:08:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[06/01 09:08:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n\u001b[32m[06/01 09:08:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[06/01 09:08:03 d2.data.common]: \u001b[0mSerializing 4363 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/01 09:08:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.90 MiB\n\u001b[32m[06/01 09:08:03 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/01 09:08:03 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n\u001b[32m[06/01 09:08:03 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_C4_1x/137257644/model_final_721ade.pkl ...\n","output_type":"stream"},{"name":"stderr","text":"model_final_721ade.pkl: 136MB [00:00, 254MB/s]                            \n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[06/01 09:08:04 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[06/01 09:08:41 d2.utils.events]: \u001b[0m eta: 10:51:02  iter: 19  total_loss: 5.491  loss_cls: 4.486  loss_box_reg: 0.5859  loss_rpn_cls: 0.1709  loss_rpn_loc: 0.2213    time: 1.6142  last_time: 1.3708  data_time: 0.4303  last_data_time: 0.1110   lr: 4.9952e-05  max_mem: 7244M\n","output_type":"stream"},{"name":"stderr","text":"2024-06-01 09:08:43.752360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-01 09:08:43.752495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-01 09:08:43.862973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[06/01 09:09:26 d2.utils.events]: \u001b[0m eta: 11:19:31  iter: 39  total_loss: 3.932  loss_cls: 2.86  loss_box_reg: 0.6131  loss_rpn_cls: 0.1508  loss_rpn_loc: 0.2112    time: 1.6935  last_time: 1.2264  data_time: 0.4251  last_data_time: 0.0110   lr: 9.9902e-05  max_mem: 7244M\n\u001b[32m[06/01 09:10:02 d2.utils.events]: \u001b[0m eta: 11:19:01  iter: 59  total_loss: 2.039  loss_cls: 1.116  loss_box_reg: 0.6065  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.1916    time: 1.7302  last_time: 1.4684  data_time: 0.4681  last_data_time: 0.0652   lr: 0.00014985  max_mem: 7245M\n\u001b[32m[06/01 09:10:39 d2.utils.events]: \u001b[0m eta: 11:18:31  iter: 79  total_loss: 1.994  loss_cls: 1.024  loss_box_reg: 0.653  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.1796    time: 1.7594  last_time: 2.6909  data_time: 0.5310  last_data_time: 1.3171   lr: 0.0001998  max_mem: 7245M\n\u001b[32m[06/01 09:11:11 d2.data.datasets.coco]: \u001b[0mLoaded 436 images in COCO format from /kaggle/input/fish-market-dataset/val.json\n\u001b[32m[06/01 09:11:11 d2.data.build]: \u001b[0mDistribution of instances among all 95 categories:\n\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n|      Rui      | 127          | Bhakur,Bhak.. | 63           | Mrigal,Mirika | 8            |\n|     Ilish     | 35           |    Chitol     | 33           |    Borali     | 4            |\n| Sippi,Pengh.. | 1            |    korang     | 1            | Kangon,Tunt.. | 1            |\n| Kundali(ass.. | 4            |     khas      | 1            |   Bou mach    | 6            |\n|     Chuno     | 6            | kaliara,kal.. | 4            |    Telapia    | 51           |\n|     Boaal     | 9            |    Nur Pur    | 4            |     Puiya     | 6            |\n|  Sapla pata   | 6            |    Shutki     | 9            | Telia(Odia).. | 11           |\n|    Borguni    | 24           | pabda,godal.. | 88           |  Pakal Mach   | 1            |\n|   Shol mach   | 46           | Karati, Cha.. | 25           |   rup chada   | 20           |\n|      Ari      | 17           |  Gura tengra  | 2            |     Litha     | 6            |\n| Bangladeshi.. | 4            | Kadali/kond.. | 5            |     bacha     | 19           |\n|    bordaia    | 1            |      koi      | 111          |     bami      | 2            |\n| Lomba chanda  | 3            |    loitta     | 10           |     tuna      | 6            |\n|     vetki     | 3            |    batasi     | 18           |    pangas     | 3            |\n|  hatir kaan   | 34           |   aom machh   | 2            |   pann mach   | 1            |\n|  sadha mach   | 2            |  chan chanda  | 16           |  sonali bata  | 24           |\n|     tapsi     | 2            |    pomfret    | 26           |  gagnga tope  | 1            |\n| Tural turi/.. | 7            |   Kholihona   | 2            |   Ptimutura   | 2            |\n|     keshi     | 1            |  Silver carp  | 6            |  Singi,Magur  | 34           |\n|    Neftani    | 3            |  Keyakeatta   | 4            |     Neria     | 5            |\n|  Nau matchee  | 2            |    Lobura     | 1            |   Phabounga   | 1            |\n|  Cheniputhi   | 2            |  Hato/Hamto   | 2            |     Bokar     | 3            |\n|  Kurhi/kuria  | 2            | Bhangone/ba.. | 152          |  Chapa Kori   | 10           |\n|   lambu/poa   | 5            |  Tolar Aandi  | 2            | Guraicha/ch.. | 51           |\n|     Baila     | 1            |  Sada Aatina  | 35           |     kakia     | 5            |\n| potka/Dicho.. | 5            |    choukya    | 5            | khorul bata.. | 11           |\n|  nuna tangra  | 8            |   kata mach   | 1            |   kukkurish   | 1            |\n|  Salo Ichalo  | 1            |    laupati    | 2            |    selkona    | 2            |\n|     Puti      | 3            |   AArikana    | 4            | Balisonda l.. | 1            |\n|      Moa      | 121          | Shillong(fi.. | 2            |   Goti poa    | 4            |\n|      eel      | 9            | horse macke.. | 9            |   kingfish    | 5            |\n|    Sardine    | 5            |     Trout     | 8            |               |              |\n|     total     | 1457         |               |              |               |              |\u001b[0m\n\u001b[32m[06/01 09:11:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[06/01 09:11:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[06/01 09:11:11 d2.data.common]: \u001b[0mSerializing 436 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/01 09:11:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/01 09:11:11 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n\u001b[32m[06/01 09:11:11 d2.utils.events]: \u001b[0m eta: 11:10:59  iter: 99  total_loss: 2.011  loss_cls: 1.003  loss_box_reg: 0.6486  loss_rpn_cls: 0.119  loss_rpn_loc: 0.1934    time: 1.7252  last_time: 1.4366  data_time: 0.2603  last_data_time: 0.0741   lr: 0.00024975  max_mem: 7245M\n\u001b[32m[06/01 09:11:45 d2.utils.events]: \u001b[0m eta: 11:10:30  iter: 119  total_loss: 1.855  loss_cls: 0.9063  loss_box_reg: 0.6214  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.1944    time: 1.7239  last_time: 1.4601  data_time: 0.4044  last_data_time: 0.1385   lr: 0.0002997  max_mem: 7245M\n\u001b[32m[06/01 09:12:20 d2.utils.events]: \u001b[0m eta: 11:14:51  iter: 139  total_loss: 1.901  loss_cls: 0.9148  loss_box_reg: 0.6597  loss_rpn_cls: 0.123  loss_rpn_loc: 0.1797    time: 1.7218  last_time: 1.4103  data_time: 0.3918  last_data_time: 0.1087   lr: 0.00034965  max_mem: 7245M\n\u001b[32m[06/01 09:12:56 d2.engine.hooks]: \u001b[0mOverall training speed: 156 iterations in 0:04:34 (1.7573 s / it)\n\u001b[32m[06/01 09:12:56 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:43 (0:00:09 on hooks)\n\u001b[32m[06/01 09:12:56 d2.utils.events]: \u001b[0m eta: 11:16:33  iter: 158  total_loss: 1.678  loss_cls: 0.8237  loss_box_reg: 0.6123  loss_rpn_cls: 0.09308  loss_rpn_loc: 0.1646    time: 1.7487  last_time: 2.5523  data_time: 0.6064  last_data_time: 1.2187   lr: 0.00039461  max_mem: 7245M\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m trainer \u001b[38;5;241m=\u001b[39m DefaultTrainer(cfg)\n\u001b[1;32m     26\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/engine/defaults.py:488\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    Run training.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mTEST\u001b[38;5;241m.\u001b[39mEXPECTED_RESULTS) \u001b[38;5;129;01mand\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    491\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_last_eval_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo evaluation results obtained during training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/engine/defaults.py:498\u001b[0m, in \u001b[0;36mDefaultTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py:332\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcurrent_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_metrics, loss_dict, data_time, \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[1;32m    330\u001b[0m     )\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03mIf you need gradient clipping/scaling or other processing, you can\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mwrap the optimizer with your custom `step()` method. But it is\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03msuboptimal as explained in https://arxiv.org/abs/2006.15704 Sec 3.2.4\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py:370\u001b[0m, in \u001b[0;36mSimpleTrainer._write_metrics\u001b[0;34m(self, loss_dict, data_time, prefix, iter)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_metric_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m         \u001b[43mSimpleTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException in writing metrics: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py:388\u001b[0m, in \u001b[0;36mSimpleTrainer.write_metrics\u001b[0;34m(loss_dict, data_time, cur_iter, prefix)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_metrics\u001b[39m(\n\u001b[1;32m    377\u001b[0m     loss_dict: Mapping[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m     prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m        loss_dict (dict): dict of scalar losses\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m        data_time (float): time taken by the dataloader iteration\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m        prefix (str): prefix for logging keys\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     metrics_dict \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m     metrics_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_time\n\u001b[1;32m    391\u001b[0m     storage \u001b[38;5;241m=\u001b[39m get_event_storage()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/engine/train_loop.py:388\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_metrics\u001b[39m(\n\u001b[1;32m    377\u001b[0m     loss_dict: Mapping[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m     prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m        loss_dict (dict): dict of scalar losses\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m        data_time (float): time taken by the dataloader iteration\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m        prefix (str): prefix for logging keys\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     metrics_dict \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m     metrics_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_time\n\u001b[1;32m    391\u001b[0m     storage \u001b[38;5;241m=\u001b[39m get_event_storage()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\ncfg.DATASETS.TEST = (\"my_dataset_test2\", )\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T08:49:03.864655Z","iopub.execute_input":"2024-06-01T08:49:03.865378Z","iopub.status.idle":"2024-06-01T08:49:04.919410Z","shell.execute_reply.started":"2024-06-01T08:49:03.865337Z","shell.execute_reply":"2024-06-01T08:49:04.918363Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[32m[06/01 08:49:04 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"test_metadata = MetadataCatalog.get(\"my_dataset_test2\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T08:49:07.867568Z","iopub.execute_input":"2024-06-01T08:49:07.868278Z","iopub.status.idle":"2024-06-01T08:49:07.872657Z","shell.execute_reply.started":"2024-06-01T08:49:07.868240Z","shell.execute_reply":"2024-06-01T08:49:07.871579Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\nimport glob\nimport cv2\n\nfor imageName in glob.glob('/content/test/*jpg'):\n  im = cv2.imread(imageName)\n  outputs = predictor(im)\n  v = Visualizer(im[:, :, ::-1],\n                metadata=test_metadata,\n                scale=0.8\n                 )\n  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n  cv2.imshow(out.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T08:49:11.840225Z","iopub.execute_input":"2024-06-01T08:49:11.840984Z","iopub.status.idle":"2024-06-01T08:49:11.847643Z","shell.execute_reply.started":"2024-06-01T08:49:11.840951Z","shell.execute_reply":"2024-06-01T08:49:11.846756Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Evaluator","metadata":{}},{"cell_type":"code","source":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\nevaluator = COCOEvaluator(\"my_dataset_test2\", (\"bbox\",), False, output_dir=\"./output/\")\nval_loader = build_detection_test_loader(cfg, \"my_dataset_test2\")\nprint(inference_on_dataset(trainer.model, val_loader, evaluator))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T08:49:15.426659Z","iopub.execute_input":"2024-06-01T08:49:15.427649Z","iopub.status.idle":"2024-06-01T08:50:55.242357Z","shell.execute_reply.started":"2024-06-01T08:49:15.427615Z","shell.execute_reply":"2024-06-01T08:50:55.241362Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[32m[06/01 08:49:15 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from /kaggle/input/fish-market-dataset/test.json\n\u001b[32m[06/01 08:49:15 d2.data.build]: \u001b[0mDistribution of instances among all 97 categories:\n\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n|      Rui      | 110          | Bhakur,Bhak.. | 95           | Mrigal,Mirika | 6            |\n|     Ilish     | 54           |    Chitol     | 37           |    Borali     | 9            |\n| Sippi,Pengh.. | 2            |    korang     | 1            | Kangon,Tunt.. | 12           |\n| Kundali(ass.. | 4            |     khas      | 1            |   Bou mach    | 3            |\n|     Chuno     | 6            | kaliara,kal.. | 12           |    Telapia    | 61           |\n|     Boaal     | 11           |    Nur Pur    | 5            |     Puiya     | 4            |\n|  Sapla pata   | 7            |    Shutki     | 2            | Telia(Odia).. | 8            |\n|    Borguni    | 16           | pabda,godal.. | 71           |  Pakal Mach   | 12           |\n|   Shol mach   | 52           | Karati, Cha.. | 2            |   rup chada   | 20           |\n|      Ari      | 31           |     Gagol     | 1            |  Gura tengra  | 8            |\n|     Litha     | 8            | Bangladeshi.. | 10           | Kadali/kond.. | 4            |\n|     bacha     | 33           |    bordaia    | 2            |      koi      | 110          |\n|     bami      | 2            | Lomba chanda  | 4            |    loitta     | 10           |\n|     tuna      | 8            |     vetki     | 4            |    batasi     | 6            |\n|    pangas     | 6            |  hatir kaan   | 11           |   aom machh   | 2            |\n|   pann mach   | 1            |  sadha mach   | 39           |  chan chanda  | 7            |\n|  sonali bata  | 4            |     tapsi     | 2            |    pomfret    | 38           |\n|  gagnga tope  | 1            | Tural turi/.. | 6            |   Kholihona   | 8            |\n|   Ptimutura   | 2            |     keshi     | 1            |  Silver carp  | 10           |\n|  Singi,Magur  | 19           |    Neftani    | 4            |  Keyakeatta   | 3            |\n|     Neria     | 13           |  Nau matchee  | 2            |    Lobura     | 1            |\n|   Phabounga   | 1            |  Cheniputhi   | 2            |  Hato/Hamto   | 2            |\n|     Bokar     | 11           |  Kurhi/kuria  | 3            | Bhangone/ba.. | 194          |\n|  Chapa Kori   | 4            |   lambu/poa   | 10           |  Tolar Aandi  | 2            |\n| Guraicha/ch.. | 28           |     Baila     | 1            |  Sada Aatina  | 14           |\n|     kakia     | 14           | potka/Dicho.. | 5            |    choukya    | 2            |\n| khorul bata.. | 2            |  nuna tangra  | 2            |   kata mach   | 2            |\n|   kukkurish   | 2            |  Salo Ichalo  | 1            |    laupati    | 2            |\n|    selkona    | 2            | mouah/bariala | 1            |     Puti      | 12           |\n|   AArikana    | 2            | Balisonda l.. | 2            |      Moa      | 137          |\n| Shillong(fi.. | 2            |   Goti poa    | 10           |      eel      | 10           |\n| horse macke.. | 9            |   kingfish    | 7            |    Sardine    | 5            |\n|     Trout     | 8            |               |              |               |              |\n|     total     | 1555         |               |              |               |              |\u001b[0m\n\u001b[32m[06/01 08:49:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[06/01 08:49:15 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[06/01 08:49:15 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n\u001b[32m[06/01 08:49:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n\u001b[32m[06/01 08:49:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 485 batches\n\u001b[32m[06/01 08:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/485. Dataloading: 0.0021 s/iter. Inference: 0.1513 s/iter. Eval: 0.0003 s/iter. Total: 0.1536 s/iter. ETA=0:01:12\n\u001b[32m[06/01 08:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 36/485. Dataloading: 0.0125 s/iter. Inference: 0.1813 s/iter. Eval: 0.0003 s/iter. Total: 0.1942 s/iter. ETA=0:01:27\n\u001b[32m[06/01 08:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 61/485. Dataloading: 0.0148 s/iter. Inference: 0.1851 s/iter. Eval: 0.0003 s/iter. Total: 0.2004 s/iter. ETA=0:01:24\n\u001b[32m[06/01 08:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 86/485. Dataloading: 0.0108 s/iter. Inference: 0.1907 s/iter. Eval: 0.0003 s/iter. Total: 0.2019 s/iter. ETA=0:01:20\n\u001b[32m[06/01 08:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 108/485. Dataloading: 0.0154 s/iter. Inference: 0.1928 s/iter. Eval: 0.0003 s/iter. Total: 0.2087 s/iter. ETA=0:01:18\n\u001b[32m[06/01 08:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 130/485. Dataloading: 0.0177 s/iter. Inference: 0.1952 s/iter. Eval: 0.0003 s/iter. Total: 0.2134 s/iter. ETA=0:01:15\n\u001b[32m[06/01 08:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 147/485. Dataloading: 0.0211 s/iter. Inference: 0.2015 s/iter. Eval: 0.0003 s/iter. Total: 0.2231 s/iter. ETA=0:01:15\n\u001b[32m[06/01 08:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 167/485. Dataloading: 0.0247 s/iter. Inference: 0.2018 s/iter. Eval: 0.0004 s/iter. Total: 0.2270 s/iter. ETA=0:01:12\n\u001b[32m[06/01 08:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 189/485. Dataloading: 0.0254 s/iter. Inference: 0.2022 s/iter. Eval: 0.0004 s/iter. Total: 0.2280 s/iter. ETA=0:01:07\n\u001b[32m[06/01 08:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 214/485. Dataloading: 0.0238 s/iter. Inference: 0.2005 s/iter. Eval: 0.0004 s/iter. Total: 0.2248 s/iter. ETA=0:01:00\n\u001b[32m[06/01 08:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 239/485. Dataloading: 0.0223 s/iter. Inference: 0.1993 s/iter. Eval: 0.0004 s/iter. Total: 0.2221 s/iter. ETA=0:00:54\n\u001b[32m[06/01 08:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 268/485. Dataloading: 0.0201 s/iter. Inference: 0.1962 s/iter. Eval: 0.0003 s/iter. Total: 0.2167 s/iter. ETA=0:00:47\n\u001b[32m[06/01 08:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 299/485. Dataloading: 0.0181 s/iter. Inference: 0.1924 s/iter. Eval: 0.0003 s/iter. Total: 0.2109 s/iter. ETA=0:00:39\n\u001b[32m[06/01 08:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 327/485. Dataloading: 0.0170 s/iter. Inference: 0.1910 s/iter. Eval: 0.0003 s/iter. Total: 0.2085 s/iter. ETA=0:00:32\n\u001b[32m[06/01 08:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 354/485. Dataloading: 0.0163 s/iter. Inference: 0.1903 s/iter. Eval: 0.0003 s/iter. Total: 0.2070 s/iter. ETA=0:00:27\n\u001b[32m[06/01 08:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 381/485. Dataloading: 0.0158 s/iter. Inference: 0.1896 s/iter. Eval: 0.0003 s/iter. Total: 0.2058 s/iter. ETA=0:00:21\n\u001b[32m[06/01 08:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 404/485. Dataloading: 0.0158 s/iter. Inference: 0.1903 s/iter. Eval: 0.0003 s/iter. Total: 0.2066 s/iter. ETA=0:00:16\n\u001b[32m[06/01 08:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 434/485. Dataloading: 0.0149 s/iter. Inference: 0.1887 s/iter. Eval: 0.0003 s/iter. Total: 0.2040 s/iter. ETA=0:00:10\n\u001b[32m[06/01 08:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 460/485. Dataloading: 0.0148 s/iter. Inference: 0.1882 s/iter. Eval: 0.0003 s/iter. Total: 0.2034 s/iter. ETA=0:00:05\n\u001b[32m[06/01 08:50:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:36.790678 (0.201647 s / iter per device, on 1 devices)\n\u001b[32m[06/01 08:50:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:29 (0.186538 s / iter per device, on 1 devices)\n\u001b[32m[06/01 08:50:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[06/01 08:50:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n\u001b[32m[06/01 08:50:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\n\u001b[32m[06/01 08:50:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n\u001b[32m[06/01 08:50:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.92 seconds.\n\u001b[32m[06/01 08:50:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n\u001b[32m[06/01 08:50:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.37 seconds.\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n\u001b[32m[06/01 08:50:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 0.023 | 0.100  | 0.000  | 0.000 | 0.000 | 0.024 |\n\u001b[32m[06/01 08:50:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category                                   | AP    | category                                   | AP    | category                | AP    |\n|:-------------------------------------------|:------|:-------------------------------------------|:------|:------------------------|:------|\n| Rui                                        | 0.377 | Bhakur,Bhakua,catla                        | 0.000 | Mrigal,Mirika           | 0.000 |\n| Ilish                                      | 0.000 | Chitol                                     | 0.000 | Borali                  | 0.000 |\n| Sippi,Pengha/pengba                        | 0.000 | korang                                     | 0.000 | Kangon,Tunti,Vacha,basa | 0.000 |\n| Kundali(assam),Chitol(bangladesh),Foli(WB) | 0.000 | khas                                       | 0.000 | Bou mach                | 0.000 |\n| Chuno                                      | 0.000 | kaliara,kalisasu,mali,mahlee               | 0.000 | Telapia                 | 0.000 |\n| Boaal                                      | 0.000 | Nur Pur                                    | 0.000 | Puiya                   | 0.000 |\n| Sapla pata                                 | 0.000 | Shutki                                     | 0.000 | Telia(Odia),ghol        | 0.000 |\n| Borguni                                    | 0.000 | pabda,godalae(kanada),khababia(khasi)      | 1.894 | Pakal Mach              | 0.000 |\n| Shol mach                                  | 0.000 | Karati, Chapila, Karoti, Khoira            | 0.000 | rup chada               | 0.000 |\n| Ari                                        | 0.000 | Gagol                                      | 0.000 | Gura tengra             | 0.000 |\n| Litha                                      | 0.000 | Bangladeshi (Native)                       | 0.000 | Kadali/kondali          | 0.000 |\n| bacha                                      | 0.000 | bordaia                                    | 0.000 | koi                     | 0.000 |\n| bami                                       | 0.000 | Lomba chanda                               | 0.000 | loitta                  | 0.000 |\n| tuna                                       | 0.000 | vetki                                      | 0.000 | batasi                  | 0.000 |\n| pangas                                     | 0.000 | hatir kaan                                 | 0.000 | aom machh               | 0.000 |\n| pann mach                                  | 0.000 | sadha mach                                 | 0.000 | chan chanda             | 0.000 |\n| sonali bata                                | 0.000 | tapsi                                      | 0.000 | pomfret                 | 0.000 |\n| gagnga tope                                | 0.000 | Tural turi/pankal(Bengali),pakal baim      | 0.000 | Kholihona               | 0.000 |\n| Ptimutura                                  | 0.000 | keshi                                      | 0.000 | Silver carp             | 0.000 |\n| Singi,Magur                                | 0.000 | Neftani                                    | 0.000 | Keyakeatta              | 0.000 |\n| Neria                                      | 0.000 | Nau matchee                                | 0.000 | Lobura                  | 0.000 |\n| Phabounga                                  | 0.000 | Cheniputhi                                 | 0.000 | Hato/Hamto              | 0.000 |\n| Bokar                                      | 0.000 | Kurhi/kuria                                | 0.000 | Bhangone/bata mach      | 0.000 |\n| Chapa Kori                                 | 0.000 | lambu/poa                                  | 0.000 | Tolar Aandi             | 0.000 |\n| Guraicha/chingri                           | 0.000 | Baila                                      | 0.000 | Sada Aatina             | 0.000 |\n| kakia                                      | 0.000 | potka/Dichotomyctere nigroviridis(english) | 0.000 | choukya                 | 0.000 |\n| khorul bata/parshe(bengali)                | 0.000 | nuna tangra                                | 0.000 | kata mach               | 0.000 |\n| kukkurish                                  | 0.000 | Salo Ichalo                                | 0.000 | laupati                 | 0.000 |\n| selkona                                    | 0.000 | mouah/bariala                              | 0.000 | Puti                    | 0.000 |\n| AArikana                                   | 0.000 | Balisonda lozola                           | 0.000 | Moa                     | 0.000 |\n| Shillong(fish)                             | 0.000 | Goti poa                                   | 0.000 | eel                     | 0.000 |\n| horse mackerel                             | 0.000 | kingfish                                   | 0.000 | Sardine                 | 0.000 |\n| Trout                                      | 0.000 |                                            |       |                         |       |\nOrderedDict([('bbox', {'AP': 0.023411053316116412, 'AP50': 0.09983284779396297, 'AP75': 0.00013596001446893686, 'APs': 0.0, 'APm': 0.0, 'APl': 0.02383109760488851, 'AP-Rui': 0.37682068398114116, 'AP-Bhakur,Bhakua,catla': 0.0, 'AP-Mrigal,Mirika': 0.0, 'AP-Ilish': 0.0, 'AP-Chitol': 0.0, 'AP-Borali': 0.0, 'AP-Sippi,Pengha/pengba': 0.0, 'AP-korang': 0.0, 'AP-Kangon,Tunti,Vacha,basa': 0.0, 'AP-Kundali(assam),Chitol(bangladesh),Foli(WB)': 0.0, 'AP-khas': 0.0, 'AP-Bou mach': 0.0, 'AP-Chuno': 0.0, 'AP-kaliara,kalisasu,mali,mahlee': 0.0, 'AP-Telapia': 0.0, 'AP-Boaal': 0.0, 'AP-Nur Pur': 0.0, 'AP-Puiya': 0.0, 'AP-Sapla pata': 0.0, 'AP-Shutki': 0.0, 'AP-Telia(Odia),ghol': 0.0, 'AP-Borguni': 0.0, 'AP-pabda,godalae(kanada),khababia(khasi)': 1.894051487682151, 'AP-Pakal Mach': 0.0, 'AP-Shol mach': 0.0, 'AP-Karati, Chapila, Karoti, Khoira': 0.0, 'AP-rup chada': 0.0, 'AP-Ari': 0.0, 'AP-Gagol': 0.0, 'AP-Gura tengra': 0.0, 'AP-Litha': 0.0, 'AP-Bangladeshi (Native)': 0.0, 'AP-Kadali/kondali': 0.0, 'AP-bacha': 0.0, 'AP-bordaia': 0.0, 'AP-koi': 0.0, 'AP-bami': 0.0, 'AP-Lomba chanda': 0.0, 'AP-loitta': 0.0, 'AP-tuna': 0.0, 'AP-vetki': 0.0, 'AP-batasi': 0.0, 'AP-pangas': 0.0, 'AP-hatir kaan': 0.0, 'AP-aom machh': 0.0, 'AP-pann mach': 0.0, 'AP-sadha mach': 0.0, 'AP-chan chanda': 0.0, 'AP-sonali bata': 0.0, 'AP-tapsi': 0.0, 'AP-pomfret': 0.0, 'AP-gagnga tope': 0.0, 'AP-Tural turi/pankal(Bengali),pakal baim': 0.0, 'AP-Kholihona': 0.0, 'AP-Ptimutura': 0.0, 'AP-keshi': 0.0, 'AP-Silver carp': 0.0, 'AP-Singi,Magur': 0.0, 'AP-Neftani': 0.0, 'AP-Keyakeatta': 0.0, 'AP-Neria': 0.0, 'AP-Nau matchee': 0.0, 'AP-Lobura': 0.0, 'AP-Phabounga': 0.0, 'AP-Cheniputhi': 0.0, 'AP-Hato/Hamto': 0.0, 'AP-Bokar': 0.0, 'AP-Kurhi/kuria': 0.0, 'AP-Bhangone/bata mach': 0.0, 'AP-Chapa Kori': 0.0, 'AP-lambu/poa': 0.0, 'AP-Tolar Aandi': 0.0, 'AP-Guraicha/chingri': 0.0, 'AP-Baila': 0.0, 'AP-Sada Aatina': 0.0, 'AP-kakia': 0.0, 'AP-potka/Dichotomyctere nigroviridis(english)': 0.0, 'AP-choukya': 0.0, 'AP-khorul bata/parshe(bengali)': 0.0, 'AP-nuna tangra': 0.0, 'AP-kata mach': 0.0, 'AP-kukkurish': 0.0, 'AP-Salo Ichalo': 0.0, 'AP-laupati': 0.0, 'AP-selkona': 0.0, 'AP-mouah/bariala': 0.0, 'AP-Puti': 0.0, 'AP-AArikana': 0.0, 'AP-Balisonda lozola': 0.0, 'AP-Moa': 0.0, 'AP-Shillong(fish)': 0.0, 'AP-Goti poa': 0.0, 'AP-eel': 0.0, 'AP-horse mackerel': 0.0, 'AP-kingfish': 0.0, 'AP-Sardine': 0.0, 'AP-Trout': 0.0})])\n","output_type":"stream"}]},{"cell_type":"code","source":"k = [\"hjk\", \"jhk\", \"jk\"]\nfor i in range(5):\n    if len(k[i])>0:\n        print(\"s\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T17:59:46.205040Z","iopub.execute_input":"2024-05-22T17:59:46.205979Z","iopub.status.idle":"2024-05-22T17:59:46.544186Z","shell.execute_reply.started":"2024-05-22T17:59:46.205945Z","shell.execute_reply":"2024-05-22T17:59:46.543083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}